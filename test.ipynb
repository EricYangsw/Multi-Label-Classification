{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericmlyang\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npick = []\\n\\nfor _ in range(20):\\n    prop = tf.constant(np.random.uniform(batch_size, data_length))\\n    gg = tf.argmax(prop, axis=1, output_type=tf.int32) #(batch_size)\\n    g1.append(gg)\\n\\n    \\n    if _ == 0:\\n        pick.append(gg)\\n    else:\\n        x = tf.stack(pick, axis=1)\\n        aa = tf.where(tf.equal(gg, x))    \\n        pp = tf.cond( tf.equal(tf.shape(aa)[0, :], 0), \\n                            true_fn=lambda: f1(gg), # True\\n                            false_fn=lambda: f2(prop, x)) # False\\n        pick.append(pp)\\n    \\n\\n    \\n    pred = tf.one_hot(pp, depth=data_length, dtype=tf.int32)\\n    label_pool = tf.add(lable_pool, pred)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1(pp):\n",
    "    return pp\n",
    "\n",
    "def f2(prop, x): \n",
    "    prop = tf.subtract(prop, tf.reduce_sum(tf.one_hot(x, depth=data_length, dtype=tf.float64), axis=0))#\n",
    "    pp = tf.argmax(prop, axis=0, output_type=tf.int64)\n",
    "    return pp\n",
    "\n",
    "batch_size = 2\n",
    "data_length = 20\n",
    "\n",
    "\n",
    "\n",
    "label_pool = tf.zeros((batch_size, data_length), dtype=tf.int32)  # (batch_size, data_length)\n",
    "\n",
    "g1 = []\n",
    "g2 = []\n",
    "for _ in range(3):\n",
    "    prop = tf.constant(np.random.uniform(low=0., high=1., size=(batch_size, data_length)))\n",
    "    gg = tf.argmax(prop, axis=1)\n",
    "    g1.append(gg)\n",
    "x = tf.stack(g1, axis=1)\n",
    "\n",
    "for i in range(3):\n",
    "    g2.append(gg)\n",
    "y = tf.stack(g2, axis=1)\n",
    "\n",
    "n1 = tf.constant(True,tf.bool)\n",
    "aa = tf.reduce_sum(tf.cast(tf.equal(y, x), dtype=tf.int32), axis=1)\n",
    "\n",
    "pp = []\n",
    "pred = []\n",
    "\n",
    "for i in range(batch_size):\n",
    "    hh = tf.cond( tf.equal(aa[i], 0), \n",
    "                    true_fn=lambda: f1(gg[i]), # True\n",
    "                    false_fn=lambda: f2(prop[i], x[i])) # False\n",
    "    \n",
    "    pred.append(tf.one_hot(hh, depth=data_length, dtype=tf.int32))\n",
    "    \n",
    "label_pool = tf.add(label_pool, tf.stack(pred, axis=0))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "pick = []\n",
    "\n",
    "for _ in range(20):\n",
    "    prop = tf.constant(np.random.uniform(batch_size, data_length))\n",
    "    gg = tf.argmax(prop, axis=1, output_type=tf.int32) #(batch_size)\n",
    "    g1.append(gg)\n",
    "\n",
    "    \n",
    "    if _ == 0:\n",
    "        pick.append(gg)\n",
    "    else:\n",
    "        x = tf.stack(pick, axis=1)\n",
    "        aa = tf.where(tf.equal(gg, x))    \n",
    "        pp = tf.cond( tf.equal(tf.shape(aa)[0, :], 0), \n",
    "                            true_fn=lambda: f1(gg), # True\n",
    "                            false_fn=lambda: f2(prop, x)) # False\n",
    "        pick.append(pp)\n",
    "    \n",
    "\n",
    "    \n",
    "    pred = tf.one_hot(pp, depth=data_length, dtype=tf.int32)\n",
    "    label_pool = tf.add(lable_pool, pred)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    print(sess.run(label_pool))\n",
    "    #print(sess.run(x), sess.run(tf.shape(x)))\n",
    "    #print(sess.run(y), sess.run(tf.shape(y)))\n",
    "    #print(sess.run(aa), sess.run(tf.shape(aa)[0]))\n",
    "    #print(sess.run(pp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_data_0.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 138)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path_input = './data/devide_data/y'\n",
    "filelist_input = os.listdir(path_input)\n",
    "data_input = pd.read_csv(path_input+'/'+filelist_input[0], index_col=0)\n",
    "data_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "global total_batch\n",
    "def train_data():   \n",
    "    #chunksize = self.config.batch_size * 500 # dataframe of iter\n",
    "    #X_train = pd.read_csv(self.config.Y_train_data, chunksize=chunksize)\n",
    "    #Y_train = pd.read_csv(self.config.X_train_data, chunksize=chunksize)\n",
    "\n",
    "    path_input = './data/devide_data/y'\n",
    "    path_label = './data/devide_data/x'\n",
    "    filelist_input = os.listdir(path_input)\n",
    "    filelist_label = os.listdir(path_label)\n",
    "    assert len(filelist_input) == len(filelist_label) #False to tigger\n",
    "\n",
    "\n",
    "    file_count = len(filelist_input)\n",
    "\n",
    "    '''Data size: [batc_size, h, w, rgb]'''\n",
    "    for no_file in range(file_count):\n",
    "        batch_input = np.zeros((32, \n",
    "                                30, \n",
    "                                138,\n",
    "                                1))\n",
    "        batch_label =  np.zeros((32,\n",
    "                             1,  # time step\n",
    "                             223))\n",
    "\n",
    "        data_input = pd.read_csv(path_input+'/'+filelist_input[no_file], index_col=0).values\n",
    "        data_label = pd.read_csv(path_label+'/'+filelist_label[no_file], index_col=0).values\n",
    "        assert data_input.shape[0] == data_label.shape[0]\n",
    "\n",
    "        data_count = data_input.shape[0]\n",
    "        print('data_count: ', data_count)\n",
    "        batch = 0\n",
    "        total_batch = 0\n",
    "        for i in range(30, data_count):\n",
    "            print(batch, ':: ',i-30 ,':',i )\n",
    "            batch_input[batch, :, :, 0] = data_input[i-30:i, :]\n",
    "            batch_label[batch, :] = data_label[i, :]\n",
    "            batch += 1\n",
    "            if batch == 32:\n",
    "                batch = 0\n",
    "                total_batch+=1\n",
    "                print(total_batch)\n",
    "                yield (batch_input, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ::  1024 : 1054\n",
      "1 ::  1025 : 1055\n",
      "2 ::  1026 : 1056\n",
      "3 ::  1027 : 1057\n",
      "4 ::  1028 : 1058\n",
      "5 ::  1029 : 1059\n",
      "6 ::  1030 : 1060\n",
      "7 ::  1031 : 1061\n",
      "8 ::  1032 : 1062\n",
      "9 ::  1033 : 1063\n",
      "10 ::  1034 : 1064\n",
      "11 ::  1035 : 1065\n",
      "12 ::  1036 : 1066\n",
      "13 ::  1037 : 1067\n",
      "14 ::  1038 : 1068\n",
      "15 ::  1039 : 1069\n",
      "16 ::  1040 : 1070\n",
      "17 ::  1041 : 1071\n",
      "18 ::  1042 : 1072\n",
      "19 ::  1043 : 1073\n",
      "20 ::  1044 : 1074\n",
      "21 ::  1045 : 1075\n",
      "22 ::  1046 : 1076\n",
      "23 ::  1047 : 1077\n",
      "24 ::  1048 : 1078\n",
      "25 ::  1049 : 1079\n",
      "26 ::  1050 : 1080\n",
      "27 ::  1051 : 1081\n",
      "28 ::  1052 : 1082\n",
      "29 ::  1053 : 1083\n",
      "30 ::  1054 : 1084\n",
      "31 ::  1055 : 1085\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "data0 = generator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
